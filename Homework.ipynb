{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name: Rohit Kulkarni                 USC ID:5402749044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pylab as pl\n",
    "import matplotlib\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from dat file, creating labels and creating dataframe for Labels AB and NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data from dat file\n",
    "with open('column_2C.dat','r') as f:\n",
    "\n",
    "    data = pd.DataFrame(l.rstrip().split() for l in f)\n",
    "\n",
    "data = data.rename(columns={0: 'PI', 1: 'PT', 2: 'LLA', 3: 'SS', 4: 'PR', 5: 'GoS', 6: 'Class'})\n",
    "CL_AB=data[data['Class'] == 'AB']\n",
    "CL_NO=data[data['Class'] == 'NO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(CL_AB['PI'], CL_AB['PT'], color='blue')\n",
    "plt.scatter(CL_NO['PI'], CL_NO['PT'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('pelvic incidence')\n",
    "plt.ylabel('pelvic tilt')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['PI'], CL_AB['LLA'], color='blue')\n",
    "plt.scatter(CL_NO['PI'], CL_NO['LLA'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('pelvic incidence')\n",
    "plt.ylabel('lumbar lordosis angle')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['PI'], CL_AB['SS'], color='blue')\n",
    "plt.scatter(CL_NO['PI'], CL_NO['SS'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('pelvic incidence')\n",
    "plt.ylabel('sacral slope')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['PI'], CL_AB['PR'], color='blue')\n",
    "plt.scatter(CL_NO['PI'], CL_NO['PR'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('pelvic incidence')\n",
    "plt.ylabel('pelvic radius')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['PI'], CL_AB['GoS'], color='blue')\n",
    "plt.scatter(CL_NO['PI'], CL_NO['GoS'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('pelvic incidence')\n",
    "plt.ylabel('grade of spondylolisthesis')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['PT'], CL_AB['LLA'], color='blue')\n",
    "plt.scatter(CL_NO['PT'], CL_NO['LLA'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('pelvic tilt')\n",
    "plt.ylabel('lumbar lordosis angle')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['PT'], CL_AB['SS'], color='blue')\n",
    "plt.scatter(CL_NO['PT'], CL_NO['SS'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('pelvic tilt')\n",
    "plt.ylabel('sacral slope')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['PT'], CL_AB['PR'], color='blue')\n",
    "plt.scatter(CL_NO['PT'], CL_NO['PR'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('pelvic tilt')\n",
    "plt.ylabel('pelvic radius')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['PT'], CL_AB['GoS'], color='blue')\n",
    "plt.scatter(CL_NO['PT'], CL_NO['GoS'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('pelvic tilt')\n",
    "plt.ylabel('grade of spondylolisthesis')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['LLA'], CL_AB['SS'], color='blue')\n",
    "plt.scatter(CL_NO['LLA'], CL_NO['SS'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('lumbar lordosis angle')\n",
    "plt.ylabel('sacral slope')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['LLA'], CL_AB['PR'], color='blue')\n",
    "plt.scatter(CL_NO['LLA'], CL_NO['PR'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('lumbar lordosis angle')\n",
    "plt.ylabel('pelvic radius')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['LLA'], CL_AB['GoS'], color='blue')\n",
    "plt.scatter(CL_NO['LLA'], CL_NO['GoS'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('lumbar lordosis angle')\n",
    "plt.ylabel('grade of spondylolisthesis')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['SS'], CL_AB['PR'], color='blue')\n",
    "plt.scatter(CL_NO['SS'], CL_NO['PR'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('sacral slope')\n",
    "plt.ylabel('pelvic radius')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['SS'], CL_AB['GoS'], color='blue')\n",
    "plt.scatter(CL_NO['SS'], CL_NO['GoS'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('sacral slope')\n",
    "plt.ylabel('grade of spondylolisthesis')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(CL_AB['PR'], CL_AB['GoS'], color='blue')\n",
    "plt.scatter(CL_NO['PR'], CL_NO['GoS'], color='red')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('pelvic radius')\n",
    "plt.ylabel('grade of spondylolisthesis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting values to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PI'] = data['PI'].astype('float64') \n",
    "data['PT'] = data['PT'].astype('float64') \n",
    "data['LLA'] = data['LLA'].astype('float64') \n",
    "data['SS'] = data['SS'].astype('float64') \n",
    "data['PR'] = data['PR'].astype('float64') \n",
    "data['GoS'] = data['GoS'].astype('float64') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying data to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanew= data[['PI','Class']].copy()\n",
    "datanew1= data[['PT','Class']].copy()\n",
    "datanew2= data[['LLA','Class']].copy()\n",
    "datanew3= data[['SS','Class']].copy()\n",
    "datanew4= data[['PR','Class']].copy()\n",
    "datanew5= data[['GoS','Class']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanew.boxplot(by='Class')\n",
    "datanew1.boxplot(by='Class')\n",
    "datanew2.boxplot(by='Class')\n",
    "datanew3.boxplot(by='Class')\n",
    "datanew4.boxplot(by='Class')\n",
    "datanew5.boxplot(by='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data=CL_AB.head(70)\n",
    "Test_data=Test_data.append(CL_NO.head(30))\n",
    "Training_Data=CL_AB.tail(140)\n",
    "Training_Data=Training_Data.append(CL_NO.tail(70))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and splitting data from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test=Test_data.iloc[:,:-1].values\n",
    "Y_Test=Test_data.iloc[:, 6].values\n",
    "X_Training=Training_Data.iloc[:,:-1].values\n",
    "Y_Training=Training_Data.iloc[:, 6].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the training to standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_Training)\n",
    "\n",
    "X_Training = scaler.transform(X_Training)\n",
    "X_Test = scaler.transform(X_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN using euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_euclidean = []\n",
    "lowest_error = []\n",
    "nk=[]\n",
    "for i in range(208,0,-3):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i,metric='euclidean')\n",
    "    knn.fit(X_Training, Y_Training)\n",
    "    pred_i_euclidean = knn.predict(X_Test)\n",
    "    error_euclidean.append(np.mean(pred_i_euclidean != Y_Test))\n",
    "    nk.append(i)\n",
    "best_k=error_euclidean.index(min(error_euclidean))\n",
    "k_star=nk[best_k]\n",
    "lowest_error.append(min(error_euclidean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the graph of error vs K value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))  \n",
    "plt.plot(range(208,0,-3), error_euclidean, color='red', linestyle='dashed', marker='o', markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')  \n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the confusion matrix for the best value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best = KNeighborsClassifier(n_neighbors=k_star,metric='euclidean')\n",
    "knn_best.fit(X_Training, Y_Training)\n",
    "y_pred = knn.predict(X_Test)\n",
    "print(confusion_matrix(Y_Test, y_pred))  \n",
    "print(classification_report(Y_Test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating and printing True positive rate and True Negative rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_Test, y_pred).ravel()\n",
    "tpr = tp/(tp+fn)\n",
    "tnr = tn/(tn+fp) \n",
    "print(\"True Positive Rate\")\n",
    "print(tpr)\n",
    "print(\"True Negative Rate\")\n",
    "print(tnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN using euclidean with N/3 training data for class 0 and N-N/3 for class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_error=[]\n",
    "min_error=[]\n",
    "for n in range(10,211,10):\n",
    "    training_rows_0=n//3\n",
    "    training_rows_1=n-(n//3)\n",
    "    Training_Data_New=CL_NO.head(training_rows_0)\n",
    "    Training_Data_New=Training_Data_New.append(CL_AB.head(training_rows_1))\n",
    "    X_Training_New=Training_Data_New.iloc[:,:-1].values\n",
    "    Y_Training_New=Training_Data_New.iloc[:, 6].values  \n",
    "    scaler.fit(X_Training_New)\n",
    "    X_Training_New = scaler.transform(X_Training_New)\n",
    "    for i in range(1,n,5):\n",
    "        knn_new = KNeighborsClassifier(n_neighbors=i,metric='euclidean')\n",
    "        knn_new.fit(X_Training_New, Y_Training_New)\n",
    "        pred_i = knn_new.predict(X_Test)\n",
    "        new_error.append(np.mean(pred_i != Y_Test))\n",
    "    min_error.append(min(new_error))\n",
    "    new_error=[]\n",
    "lowest_error.append(min(min_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))  \n",
    "plt.plot(range(1,211,10), min_error, color='red', linestyle='dashed', marker='o', markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')  \n",
    "plt.xlabel('K Value')  \n",
    "plt.ylabel('Best test error rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating data for Minkowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test_minkowski=Test_data.iloc[:,:-1].values\n",
    "Y_Testminkowski=Test_data.iloc[:, 6].values\n",
    "X_Training_minkowski=Training_Data.iloc[:,:-1].values\n",
    "Y_Training_minkowski=Training_Data.iloc[:, 6].values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_Training_minkowski)\n",
    "X_Training_minkowski = scaler.transform(X_Training_minkowski)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minkowski distance which is Manhattan when p=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_manhattan = []\n",
    "k=[]\n",
    "summary_table=pd.DataFrame(columns=['Distance Metric','Best K','Test Error'])\n",
    "for i in range(1,197,5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i,metric='manhattan')\n",
    "    knn.fit(X_Training_minkowski, Y_Training_minkowski)\n",
    "    pred_manhattan = knn.predict(X_Test)\n",
    "    error_manhattan.append(np.mean(pred_manhattan != Y_Test))\n",
    "    k.append(i)\n",
    "best_k=error_manhattan.index(min(error_manhattan))\n",
    "k_star=k[best_k]\n",
    "lowest_error.append(min(error_manhattan))\n",
    "summary_table=summary_table.append({'Distance Metric':'Manhattan distance when p =1','Best K':k_star,'Test Error':min(error_manhattan)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manhattan for log as p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_minkowski_log=[]\n",
    "k_manhattan=[]\n",
    "for i in np.arange(0.1, 1.1, 0.1):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_star,p=i,metric='manhattan')\n",
    "    knn.fit(X_Training_minkowski, Y_Training_minkowski)\n",
    "    pred_minkowski_log = knn.predict(X_Test)\n",
    "    error_minkowski_log.append(np.mean(pred_minkowski_log != Y_Test))\n",
    "    k_manhattan.append(i)\n",
    "best_k=error_minkowski_log.index(min(error_minkowski_log))\n",
    "k_star_manhattan=k_manhattan[best_k]\n",
    "lowest_error.append(min(error_minkowski_log))\n",
    "summary_table=summary_table.append({'Distance Metric':'Manhattan distance with log values as p','Best K':k_star,'Test Error':min(error_minkowski_log)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN using Chebyshev distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_Chebyshev=[]\n",
    "k_chebyshev=[]\n",
    "for i in range(1,197,5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i,metric='chebyshev')\n",
    "    knn.fit(X_Training_minkowski, Y_Training_minkowski)\n",
    "    pred_Chebyshev = knn.predict(X_Test)\n",
    "    error_Chebyshev.append(np.mean(pred_Chebyshev != Y_Test))\n",
    "    k_chebyshev.append(i)\n",
    "best_k=error_Chebyshev.index(min(error_Chebyshev))\n",
    "k_star_chebyshev=k_chebyshev[best_k]\n",
    "lowest_error.append(min(error_Chebyshev))\n",
    "summary_table=summary_table.append({'Distance Metric':'Chebyshev Distance','Best K':k_star,'Test Error':min(error_Chebyshev)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN using Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_Mahalanobis=[]\n",
    "k_mahalanobis=[]\n",
    "for i in range(1,197,5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i,metric='mahalanobis',metric_params={'V': np.cov(X_Training)},algorithm='brute')\n",
    "    knn.fit(X_Training,Y_Training)\n",
    "    pred_Mahalanobis = knn.predict(X_Test)\n",
    "    error_Mahalanobis.append(np.mean(pred_Mahalanobis != Y_Test))\n",
    "    k_mahalanobis.append(i)\n",
    "best_k=error_Mahalanobis.index(min(error_Mahalanobis))\n",
    "k_star_chebyshev=k_mahalanobis[best_k]\n",
    "lowest_error.append(min(error_Mahalanobis))\n",
    "summary_table=summary_table.append({'Distance Metric':'Mahalanobis Distance','Best K':k_star,'Test Error':min(error_Mahalanobis)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing the test errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN using Euclidean as distance and weight is distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_euclidean_weighted=[]\n",
    "nk_euclidean=[]\n",
    "for i in range(1,197,5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i,weights='distance',metric='euclidean')\n",
    "    knn.fit(X_Training, Y_Training)\n",
    "    pred_i_euclidean_weighted = knn.predict(X_Test)\n",
    "    error_euclidean_weighted.append(np.mean(pred_i_euclidean_weighted != Y_Test))\n",
    "    nk_euclidean.append(i)\n",
    "best_k_euclidean_weighted=error_euclidean_weighted.index(min(error_euclidean_weighted))\n",
    "k_star_euclidean_weighted=nk_euclidean[best_k_euclidean_weighted]\n",
    "lowest_error.append(min(error_euclidean_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN using Manhattan as distance and weight is distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_manhattan_weighted=[]\n",
    "nk_manhattan_weighted=[]\n",
    "for i in range(1,197,5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i,weights='distance',metric='manhattan')\n",
    "    knn.fit(X_Training_minkowski, Y_Training_minkowski)\n",
    "    pred_manhattan_weighted = knn.predict(X_Test)\n",
    "    error_manhattan_weighted.append(np.mean(pred_manhattan_weighted != Y_Test))\n",
    "    nk_manhattan_weighted.append(i)\n",
    "best_k_manhattan_weighted=error_manhattan_weighted.index(min(error_manhattan_weighted))\n",
    "k_star_manhattan_weighted=nk_manhattan_weighted[best_k_manhattan_weighted]\n",
    "lowest_error.append(min(error_manhattan_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN using Chebyshev as distance and weight is distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_Chebyshev_weighted=[]\n",
    "nk_Chebyshev_weighted=[]\n",
    "for i in range(1,197,5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i,weights='distance',metric='chebyshev')\n",
    "    knn.fit(X_Training_minkowski, Y_Training_minkowski)\n",
    "    pred_Chebyshev_weighted = knn.predict(X_Test)\n",
    "    error_Chebyshev_weighted.append(np.mean(pred_Chebyshev_weighted != Y_Test))\n",
    "    nk_Chebyshev_weighted.append(i)\n",
    "best_k_Chebyshev_weighted=error_Chebyshev_weighted.index(min(error_Chebyshev_weighted))\n",
    "k_star_Chebyshev_weighted=nk_Chebyshev_weighted[best_k_Chebyshev_weighted]\n",
    "lowest_error.append(min(error_Chebyshev_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best test error achieved in this homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(lowest_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
